#!/usr/bin/env python3
"""
Pre-Quest Example 2: Sentence Transformers
Aprende cÃ³mo usar modelos pre-entrenados para convertir texto a vectores
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.metrics.pairwise import cosine_similarity
import warnings
warnings.filterwarnings('ignore')

def verificar_instalacion():
    """
    Verificar si sentence-transformers estÃ¡ instalado
    """
    try:
        from sentence_transformers import SentenceTransformer
        return True
    except ImportError:
        print("âŒ sentence-transformers no estÃ¡ instalado")
        print("ğŸ“¥ Instalar con: pip install sentence-transformers")
        return False

def ejemplo_embeddings_basicos():
    """
    ğŸ¯ Objetivo: Generar embeddings con sentence-transformers
    """
    if not verificar_instalacion():
        return None
    
    from sentence_transformers import SentenceTransformer
    
    print("ğŸ¤– EJEMPLO 1: Embeddings con Sentence Transformers")
    print("=" * 60)
    
    # Cargar modelo pre-entrenado
    print("ğŸ“¥ Cargando modelo 'all-MiniLM-L6-v2'...")
    model = SentenceTransformer('all-MiniLM-L6-v2')
    print("âœ… Modelo cargado exitosamente")
    
    # Frases de ejemplo
    frases = [
        "El gato estÃ¡ durmiendo en el sofÃ¡",
        "Un felino descansa en el mueble",
        "El perro ladra en el jardÃ­n",
        "Un canino hace ruido afuera",
        "Me gusta programar en Python",
        "Disfruto codificar con Python",
        "El clima estÃ¡ soleado hoy",
        "Llueve mucho esta maÃ±ana"
    ]
    
    print(f"\nğŸ“ Procesando {len(frases)} frases...")
    
    # Generar embeddings
    embeddings = model.encode(frases)
    
    print(f"âœ… Embeddings generados!")
    print(f"ğŸ“ DimensiÃ³n de cada vector: {embeddings.shape[1]}")
    print(f"ğŸ”¢ Forma del array: {embeddings.shape}")
    
    # Mostrar informaciÃ³n de cada embedding
    for i, (frase, embedding) in enumerate(zip(frases, embeddings)):
        print(f"\nğŸ”¤ Frase {i+1}: '{frase}'")
        print(f"ğŸ”¢ Vector (primeros 5 valores): {embedding[:5]}")
        print(f"ğŸ“Š Magnitud del vector: {np.linalg.norm(embedding):.3f}")
    
    return frases, embeddings, model

def calcular_similitudes_embeddings(frases, embeddings):
    """
    ğŸ¯ Objetivo: Calcular similitudes entre embeddings
    """
    print("\n\nğŸ” EJEMPLO 2: Similitudes entre Embeddings")
    print("=" * 60)
    
    # Calcular matriz de similitudes
    similitudes = cosine_similarity(embeddings)
    
    print("ğŸ“Š Matriz de similitudes (solo valores > 0.5):")
    print("   ", "  ".join([f"{i:2d}" for i in range(len(frases))]))
    
    for i in range(len(frases)):
        fila = f"{i:2d} "
        for j in range(len(frases)):
            if similitudes[i, j] > 0.5:
                fila += f"{similitudes[i, j]:.2f} "
            else:
                fila += "---- "
        print(fila)
    
    # Encontrar pares mÃ¡s similares
    print("\nğŸ† Top 5 pares mÃ¡s similares:")
    pares_similitud = []
    
    for i in range(len(frases)):
        for j in range(i+1, len(frases)):
            pares_similitud.append((
                similitudes[i, j], 
                i, j, 
                frases[i][:30] + "...", 
                frases[j][:30] + "..."
            ))
    
    # Ordenar por similitud descendente
    pares_similitud.sort(reverse=True)
    
    for idx, (sim, i, j, frase1, frase2) in enumerate(pares_similitud[:5]):
        print(f"{idx+1}. Similitud: {sim:.3f}")
        print(f"   ğŸ“ '{frase1}' â†” '{frase2}'")

def comparar_metodos_vectorizacion():
    """
    ğŸ¯ Objetivo: Comparar diferentes mÃ©todos de vectorizaciÃ³n
    """
    print("\n\nâš–ï¸ EJEMPLO 3: ComparaciÃ³n de MÃ©todos")
    print("=" * 60)
    
    if not verificar_instalacion():
        return
    
    from sentence_transformers import SentenceTransformer
    from sklearn.feature_extraction.text import TfidfVectorizer
    
    # Frases para comparar
    frases = [
        "gato animal domÃ©stico",
        "felino mascota casa",
        "perro animal leal",
        "canino mascota fiel"
    ]
    
    print("ğŸ“ Frases de prueba:")
    for i, frase in enumerate(frases):
        print(f"   {i+1}. '{frase}'")
    
    # MÃ©todo 1: TF-IDF (tradicional)
    print("\nğŸ“Š MÃ©todo 1: TF-IDF")
    vectorizer = TfidfVectorizer()
    tfidf_vectors = vectorizer.fit_transform(frases).toarray()
    
    # Similitud entre frases 1 y 2 (gato vs felino)
    sim_tfidf = cosine_similarity([tfidf_vectors[0]], [tfidf_vectors[1]])[0][0]
    print(f"   Similitud 'gato animal' vs 'felino mascota': {sim_tfidf:.3f}")
    
    # MÃ©todo 2: Sentence Transformers
    print("\nğŸ¤– MÃ©todo 2: Sentence Transformers")
    model = SentenceTransformer('all-MiniLM-L6-v2')
    st_vectors = model.encode(frases)
    
    sim_st = cosine_similarity([st_vectors[0]], [st_vectors[1]])[0][0]
    print(f"   Similitud 'gato animal' vs 'felino mascota': {sim_st:.3f}")
    
    print("\nğŸ’¡ Observaciones:")
    print(f"   â€¢ TF-IDF: {sim_tfidf:.3f} (basado en palabras exactas)")
    print(f"   â€¢ Sentence Transformers: {sim_st:.3f} (entiende significado)")
    print("   â€¢ Sentence Transformers captura mejor la semÃ¡ntica!")

def busqueda_semantica_ejemplo():
    """
    ğŸ¯ Objetivo: Demostrar bÃºsqueda semÃ¡ntica
    """
    print("\n\nğŸ” EJEMPLO 4: BÃºsqueda SemÃ¡ntica")
    print("=" * 60)
    
    if not verificar_instalacion():
        return
    
    from sentence_transformers import SentenceTransformer
    
    # Base de datos de documentos
    documentos = [
        "Python es un lenguaje de programaciÃ³n versÃ¡til y fÃ¡cil de aprender",
        "La inteligencia artificial estÃ¡ revolucionando la tecnologÃ­a",
        "Los gatos son animales independientes y cariÃ±osos",
        "Machine learning utiliza algoritmos para aprender de datos",
        "Los perros son leales compaÃ±eros de los humanos",
        "JavaScript es popular para desarrollo web",
        "Las redes neuronales imitan el funcionamiento del cerebro",
        "Los felinos son cazadores naturales muy eficientes",
        "React es una biblioteca de JavaScript para interfaces",
        "El deep learning es una rama del machine learning"
    ]
    
    print(f"ğŸ“š Base de datos: {len(documentos)} documentos")
    
    # Cargar modelo y generar embeddings
    model = SentenceTransformer('all-MiniLM-L6-v2')
    doc_embeddings = model.encode(documentos)
    
    # Consultas de prueba
    consultas = [
        "programaciÃ³n y cÃ³digo",
        "animales domÃ©sticos",
        "inteligencia artificial"
    ]
    
    for consulta in consultas:
        print(f"\nğŸ” Consulta: '{consulta}'")
        
        # Generar embedding de la consulta
        consulta_embedding = model.encode([consulta])
        
        # Calcular similitudes
        similitudes = cosine_similarity(consulta_embedding, doc_embeddings)[0]
        
        # Encontrar top 3 mÃ¡s similares
        indices_top = np.argsort(similitudes)[::-1][:3]
        
        print("   ğŸ“Š Top 3 resultados:")
        for i, idx in enumerate(indices_top):
            print(f"   {i+1}. Similitud: {similitudes[idx]:.3f}")
            print(f"      ğŸ“„ '{documentos[idx]}'")

def visualizar_embeddings():
    """
    ğŸ¯ Objetivo: Visualizar embeddings en 2D
    """
    print("\n\nğŸ“ˆ EJEMPLO 5: VisualizaciÃ³n de Embeddings")
    print("=" * 60)
    
    if not verificar_instalacion():
        return
    
    from sentence_transformers import SentenceTransformer
    
    # Frases agrupadas por temas
    frases = [
        # TecnologÃ­a
        "programaciÃ³n en Python",
        "desarrollo de software", 
        "inteligencia artificial",
        # Animales
        "gatos domÃ©sticos",
        "perros leales",
        "animales de compaÃ±Ã­a",
        # Comida
        "pizza italiana deliciosa",
        "pasta con salsa",
        "comida mediterrÃ¡nea",
        # Deportes
        "fÃºtbol y goles",
        "baloncesto profesional",
        "deportes de equipo"
    ]
    
    categorias = ["tech", "tech", "tech", "animals", "animals", "animals", 
                 "food", "food", "food", "sports", "sports", "sports"]
    
    # Generar embeddings
    model = SentenceTransformer('all-MiniLM-L6-v2')
    embeddings = model.encode(frases)
    
    # Reducir dimensionalidad con PCA
    pca = PCA(n_components=2)
    embeddings_2d = pca.fit_transform(embeddings)
    
    # Crear grÃ¡fico
    plt.figure(figsize=(12, 8))
    
    colores = {'tech': 'red', 'animals': 'blue', 'food': 'green', 'sports': 'orange'}
    
    for categoria in set(categorias):
        indices = [i for i, cat in enumerate(categorias) if cat == categoria]
        x = [embeddings_2d[i][0] for i in indices]
        y = [embeddings_2d[i][1] for i in indices]
        plt.scatter(x, y, c=colores[categoria], label=categoria, s=100, alpha=0.7)
        
        # AÃ±adir etiquetas
        for i in indices:
            plt.annotate(frases[i][:15] + "...", 
                        (embeddings_2d[i][0], embeddings_2d[i][1]),
                        xytext=(5, 5), textcoords='offset points', fontsize=8)
    
    plt.xlabel('Componente Principal 1')
    plt.ylabel('Componente Principal 2')
    plt.title('VisualizaciÃ³n de Embeddings por CategorÃ­as')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    try:
        plt.tight_layout()
        plt.savefig('/home/andy/quicksight/vectorDb/src/preQuest/embeddings_visualization.png', 
                   dpi=150, bbox_inches='tight')
        plt.show()
        print("ğŸ’¾ GrÃ¡fico guardado como 'embeddings_visualization.png'")
    except Exception as e:
        print(f"âš ï¸ No se pudo crear el grÃ¡fico: {e}")

def main():
    """
    Ejecutar todos los ejemplos
    """
    print("ğŸ¤– PRE-QUEST: Sentence Transformers")
    print("ğŸ¯ Embeddings profesionales con modelos pre-entrenados")
    print("=" * 80)
    
    # Verificar instalaciÃ³n
    if not verificar_instalacion():
        print("\nğŸ’¡ Para instalar sentence-transformers:")
        print("   pip install sentence-transformers")
        print("\nğŸ® Mientras tanto, puedes ejecutar 01_manual_vectors.py")
        return
    
    # Ejecutar ejemplos
    frases, embeddings, model = ejemplo_embeddings_basicos()
    if embeddings is not None:
        calcular_similitudes_embeddings(frases, embeddings)
        comparar_metodos_vectorizacion()
        busqueda_semantica_ejemplo()
        
        try:
            visualizar_embeddings()
        except Exception as e:
            print(f"âš ï¸ Error en visualizaciÃ³n: {e}")
    
    print("\n\nğŸ‰ Â¡Ejemplos de Sentence Transformers completados!")
    print("ğŸ’¡ Conceptos clave aprendidos:")
    print("   â€¢ Modelos pre-entrenados para embeddings")
    print("   â€¢ Embeddings densos vs sparse")
    print("   â€¢ Similitud semÃ¡ntica vs similitud lÃ©xica")
    print("   â€¢ BÃºsqueda semÃ¡ntica en documentos")
    print("   â€¢ VisualizaciÃ³n de espacios vectoriales")
    print("\nğŸ® Â¡Ahora tienes las bases para Quest 2: Real Vector Database!")

if __name__ == "__main__":
    main()